{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f0900bc-db29-4883-a13c-f1070d1b9ff0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 0. Dependencies\n",
    "This notebook requires three dependencies to work properly, all three which are publicly available:\n",
    "1. Jupyter kernel containing the python package dependencies below. The easiest way to install a functioning kernel is to follow the step-by-step explanation in notebook `0_resources.ipynb`.\n",
    "2. Region sets which can be used to calculate FRIP. You can either supply your own (e.g. generate from peak calling on aggregate data from your samples, or previous experiments), or use the ENCODE SCREEN regions, which can be downloaded from `PUMATAC_dependencies` (see notebook `0_resources.ipynb`)\n",
    "3. Aligned fragments files. These can be generated using either `PUMATAC` or `cellranger`, or your own tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725fa6e7-ecfc-4864-8386-fa9e05318243",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "\n",
    "import pycisTopic\n",
    "import glob\n",
    "import os\n",
    "import pybiomart as pbm\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from pycisTopic.qc import *\n",
    "from IPython.display import Image, display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import palettable\n",
    "import importlib\n",
    "import pypumatac as pum  # this loads the main functions needed in this notebook.\n",
    "\n",
    "import pprint as pp\n",
    "import polars as pl\n",
    "from IPython.display import Image, display\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext jupyter_black"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00440631-53fe-4605-a4b5-f444666a7a15",
   "metadata": {},
   "source": [
    "# 1. Run basic cisTopic analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6321d18-d4c8-4865-bea3-dc39ede50d40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-14T14:22:11.125306Z",
     "iopub.status.busy": "2023-04-14T14:22:11.124904Z",
     "iopub.status.idle": "2023-04-14T14:22:11.128664Z",
     "shell.execute_reply": "2023-04-14T14:22:11.128117Z",
     "shell.execute_reply.started": "2023-04-14T14:22:11.125281Z"
    }
   },
   "source": [
    "### Find paths to fragments\n",
    "First, we will need to locate the most important files: the `fragments.tsv.gz` files for each sample! This notebook assumes that you have placed either `PUMATAC` or `cellranger` output directories within a single output directory:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c98f57b-739d-4c24-9966-1c196c6c91bc",
   "metadata": {},
   "source": [
    "The `PUMATAC` output should look like so (showing directories):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb894015-bcf9-463f-b99e-0f082a18858e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pumatac_output_dir = \"PUMATAC_out\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7be028-5726-4a75-920e-2e4185cc528b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pum.list_files(pumatac_output_dir, maxlevel=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cc7ab1-21a8-4a8f-b2f2-65268a70a2d8",
   "metadata": {},
   "source": [
    "All fragments files of all samples are located within the `fragments/` directory.  \n",
    "The Cellranger output should look like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12ef77d-75c0-4255-be9e-d3eda5e573ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cr_output_dir = \"cellranger_out\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e85332-2d85-4dcd-8960-64c78f2788ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pum.list_files(cr_output_dir, maxlevel=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3942555a-3740-414c-9647-fd1faad09a0f",
   "metadata": {},
   "source": [
    "Each subdirectory of `cellranger_out` contains one sample's cellranger output.  \n",
    "We now get the paths to the fragments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59140776-f5d3-436d-9cc1-0910f8b1f1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "optional_filter = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9663deda-acb7-47a1-a15c-6ca18c6d068e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline_dict = {}\n",
    "fragments_path_dict = {\n",
    "    os.path.basename(x).split(\".fragments.tsv.gz\")[0]: x\n",
    "    for x in sorted(\n",
    "        glob.glob(\n",
    "            f\"{pumatac_output_dir}/data/fragments/*{optional_filter}*fragments.tsv.gz\"\n",
    "        )\n",
    "    )\n",
    "}\n",
    "for x in fragments_path_dict.keys():\n",
    "    pipeline_dict[x] = \"PUMATAC\"\n",
    "\n",
    "cr_atac_fragments_path_dict = {\n",
    "    x.split(\"/\")[-3]: x\n",
    "    for x in sorted(\n",
    "        glob.glob(f\"{cr_output_dir}/*{optional_filter}*/outs/fragments.tsv.gz\")\n",
    "    )\n",
    "}\n",
    "for x in cr_atac_fragments_path_dict.keys():\n",
    "    pipeline_dict[x] = \"cellranger-atac\"\n",
    "\n",
    "cr_arc_fragments_path_dict = {\n",
    "    x.split(\"/\")[-3]: x\n",
    "    for x in sorted(\n",
    "        glob.glob(f\"{cr_output_dir}/*{optional_filter}*/outs/atac_fragments.tsv.gz\")\n",
    "    )\n",
    "}\n",
    "for x in cr_arc_fragments_path_dict.keys():\n",
    "    pipeline_dict[x] = \"cellranger-arc\"\n",
    "\n",
    "fragments_path_dict.update(cr_atac_fragments_path_dict)\n",
    "fragments_path_dict.update(cr_arc_fragments_path_dict)\n",
    "fragments_path_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72919991-29b1-41e5-aa66-49f3386f7cf6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-22T16:15:38.492919Z",
     "iopub.status.busy": "2023-06-22T16:15:38.492593Z",
     "iopub.status.idle": "2023-06-22T16:15:38.497664Z",
     "shell.execute_reply": "2023-06-22T16:15:38.496333Z",
     "shell.execute_reply.started": "2023-06-22T16:15:38.492899Z"
    }
   },
   "source": [
    "Meanwhile, we also defined which pipeline was used for which sample (will affect where some files are stored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c74fe4d-7e39-4220-a524-abbc115edecb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747ba82f-68b2-42fd-b13a-6d7768434534",
   "metadata": {},
   "source": [
    "And we now also have all the samples, which are all keys of the `fragments_path_dict` dictionary. Later, samples will be plotted in this order specific order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cafe61-d067-4947-8960-92d81d81ba9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "samples = sorted(list(fragments_path_dict.keys()))\n",
    "samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e395722f-1bc7-40ff-99d9-db86cb144c4b",
   "metadata": {},
   "source": [
    "We can define an alias dictionary here, for shorter names in titles of plots etc.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85f853e-4ae8-4533-9776-3f9957f2bb5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "alias_dict = {x: x for x in samples}\n",
    "alias_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d53def-8283-45a3-9d60-627fc2afea26",
   "metadata": {},
   "source": [
    "Edit your aliases below. You can copy-paste the basic `alias_dict`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476b7907-4499-4afe-9ecc-4a7aabc3a06b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# alias_dict = {\"x1226_2\": \"x1226_2\", \"x1226_4\": \"x1226_4\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31e22b2-62c2-423c-a427-cd2ee9e45bf2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-14T14:30:01.154833Z",
     "iopub.status.busy": "2023-04-14T14:30:01.154459Z",
     "iopub.status.idle": "2023-04-14T14:30:01.158049Z",
     "shell.execute_reply": "2023-04-14T14:30:01.157489Z",
     "shell.execute_reply.started": "2023-04-14T14:30:01.154809Z"
    }
   },
   "source": [
    "### Define which genome should be used for each sample\n",
    "Valid values for this notebook are `hg38`, `mm10` and `dm6`. If you use any of these three values, the notebook will download genome annotations for these genomes. If you work with other genomes, you can manually add gene annotation and regions as you please)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e046e7-2f9d-42ad-8430-b733531583d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "standard_genome = \"GRCh38_mm10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d481f655-82ee-46b7-87af-6149edcab156",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "genome_dict = {x: standard_genome for x in samples}\n",
    "genome_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5e78dd-5d0f-43f9-a754-a8f3a4048a41",
   "metadata": {},
   "source": [
    "Manually set the real `genome_dict` here (valid values are `hg37`, `hg38` or `dm6`). If you add a non-standard genome, you will have to provide your own genome annotation later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fa340b-1f4e-4a4d-8c5c-8238bc652eea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# genome_dict = {\"x1226_2\": \"GRCh38_mm10\", \"x1226_4\": \"GRCh38_mm10\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f71569e-f10c-46fa-b5b8-eea56284bb8f",
   "metadata": {},
   "source": [
    "Check if all samples are included:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5885b29-82ff-4699-a374-39779acc0937",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not set(genome_dict.keys()) == set(samples):\n",
    "    print(\"Warning, not all fragments files have genomes defined.\")\n",
    "else:\n",
    "    print(\"Genomes defined for all fragments files!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e568c254-af05-443d-b36c-dbb7cf111960",
   "metadata": {},
   "source": [
    "Create an inverse dictionary, listing the samples per genome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96261edb-45b4-4e1f-bfa3-aeb82041190e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inverse_genome_dict = {}\n",
    "\n",
    "for sample in samples:\n",
    "    genome = genome_dict[sample]\n",
    "    if genome not in inverse_genome_dict:\n",
    "        inverse_genome_dict[genome] = []\n",
    "    inverse_genome_dict[genome].append(sample)\n",
    "\n",
    "inverse_genome_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b783910f-ffd6-4257-afc4-f28a9858f59c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-14T14:33:13.275309Z",
     "iopub.status.busy": "2023-04-14T14:33:13.274918Z",
     "iopub.status.idle": "2023-04-14T14:33:13.278972Z",
     "shell.execute_reply": "2023-04-14T14:33:13.278031Z",
     "shell.execute_reply.started": "2023-04-14T14:33:13.275285Z"
    }
   },
   "source": [
    "### Download a gene annotation from biomart\n",
    "We need gene annotations to calculate TSS enrichment of fragments later. The following code will work for `hg38`, `hg37`, `mm10` and `dm6`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97affc6-24c7-41fc-8030-30380bed83e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "annotation_dict = pum.download_genome_annotation(inverse_genome_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceca43a1-286c-4649-80ac-105cc927f608",
   "metadata": {},
   "source": [
    "A genome annotation should looks like so, in case you want to add your own:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca1ef96-c445-497e-9aa7-7d1ae35bb224",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Compile a hybrid gene annotation from biomart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64110e37-151c-4bcd-b51a-3f7756da5440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For mouse mm10\n",
    "# dataset = pbm.Dataset(name='mmusculus_gene_ensembl',  host='http://nov2020.archive.ensembl.org/')\n",
    "# For human\n",
    "dataset = pbm.Dataset(name=\"hsapiens_gene_ensembl\", host=\"http://www.ensembl.org\")\n",
    "# dataset = pbm.Dataset(name='hsapiens_gene_ensembl',  host='http://grch37.ensembl.org/')\n",
    "# For fly\n",
    "# dataset = pbm.Dataset(name='dmelanogaster_gene_ensembl',  host='http://www.ensembl.org')\n",
    "annot = dataset.query(\n",
    "    attributes=[\n",
    "        \"chromosome_name\",\n",
    "        \"transcription_start_site\",\n",
    "        \"strand\",\n",
    "        \"external_gene_name\",\n",
    "        \"transcript_biotype\",\n",
    "    ]\n",
    ")\n",
    "filter = annot[\"Chromosome/scaffold name\"].str.contains(\"CHR|GL|JH|MT\")\n",
    "annot = annot[~filter]\n",
    "annot[\"Chromosome/scaffold name\"] = annot[\"Chromosome/scaffold name\"].str.replace(\n",
    "    r\"(\\b\\S)\", r\"chr\\1\"\n",
    ")\n",
    "annot.columns = [\"Chromosome\", \"Start\", \"Strand\", \"Gene\", \"Transcript_type\"]\n",
    "annot_human = annot[annot.Transcript_type == \"protein_coding\"]\n",
    "annot_human[\"Chromosome\"] = annot_human[\"Chromosome\"].str.replace(\n",
    "    \"^chr\", \"GRCh38_chr\", regex=True\n",
    ")\n",
    "annot_human[\"Chromosome\"] = [\"GRCh38_chr\" + x for x in annot_human[\"Chromosome\"]]\n",
    "annot_human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe997e1-698f-40ad-bdbd-e70b382392bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For mouse mm10\n",
    "dataset = pbm.Dataset(\n",
    "    name=\"mmusculus_gene_ensembl\", host=\"http://nov2020.archive.ensembl.org/\"\n",
    ")\n",
    "# For human\n",
    "# dataset = pbm.Dataset(name='hsapiens_gene_ensembl',  host='http://www.ensembl.org')\n",
    "# dataset = pbm.Dataset(name='hsapiens_gene_ensembl',  host='http://grch37.ensembl.org/')\n",
    "# For fly\n",
    "# dataset = pbm.Dataset(name='dmelanogaster_gene_ensembl',  host='http://www.ensembl.org')\n",
    "annot = dataset.query(\n",
    "    attributes=[\n",
    "        \"chromosome_name\",\n",
    "        \"transcription_start_site\",\n",
    "        \"strand\",\n",
    "        \"external_gene_name\",\n",
    "        \"transcript_biotype\",\n",
    "    ]\n",
    ")\n",
    "filter = annot[\"Chromosome/scaffold name\"].str.contains(\"CHR|GL|JH|MT\")\n",
    "annot = annot[~filter]\n",
    "annot[\"Chromosome/scaffold name\"] = annot[\"Chromosome/scaffold name\"].str.replace(\n",
    "    r\"(\\b\\S)\", r\"chr\\1\"\n",
    ")\n",
    "annot.columns = [\"Chromosome\", \"Start\", \"Strand\", \"Gene\", \"Transcript_type\"]\n",
    "annot_mouse = annot[annot.Transcript_type == \"protein_coding\"]\n",
    "annot_mouse[\"Chromosome\"] = annot_mouse[\"Chromosome\"].str.replace(\n",
    "    \"^chr\", \"mm10_chr\", regex=True\n",
    ")\n",
    "annot_mouse[\"Chromosome\"] = [\"mm10_chr\" + x for x in annot_mouse[\"Chromosome\"]]\n",
    "\n",
    "annot_mouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f16607-c42f-4252-a299-7647f6ccfbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "annot_human_mouse = pd.concat([annot_human, annot_mouse])\n",
    "annot_human_mouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5398ef53-bd72-45f6-bb93-35e661d953d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_dict[\"GRCh38_mm10\"] = annot_human_mouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d002640c-4e8c-4696-9282-be86f3cf2fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "annot_human_mouse = pd.read_csv(\"annot_human_mouse.tsv\", sep=\"\\t\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9b88c7-d53e-4a4f-b478-21905bc3801d",
   "metadata": {},
   "outputs": [],
   "source": [
    "annot_human_mouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1203c508-048b-44e5-8ae0-f3e112cb4560",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_dict = {}\n",
    "annotation_dict[\"GRCh38_mm10\"] = annot_human_mouse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433ff157-490b-46bf-a7b5-51adf85b09d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-04T09:25:52.602121Z",
     "iopub.status.busy": "2023-05-04T09:25:52.601694Z",
     "iopub.status.idle": "2023-05-04T09:25:52.607306Z",
     "shell.execute_reply": "2023-05-04T09:25:52.606729Z",
     "shell.execute_reply.started": "2023-05-04T09:25:52.602052Z"
    }
   },
   "source": [
    "### Make sure that the chromosome names in your annotation match the chromosome names in your fragments files.\n",
    "Depending on the genome index you use, the prefix `chr` may be omitted in your fragments files. You can check this via the following cell, which checks which chromosomes are present here. Note that this code can take a few minutes per fragments file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fe5693-5841-43a5-b98a-4e5c79df3c1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "check_fragments = False\n",
    "\n",
    "if check_fragments:\n",
    "    for sample in samples:\n",
    "        file = fragments_path_dict[sample]\n",
    "        fragments_df = pum.read_bc_and_counts_from_fragments_file(file)\n",
    "        chromosomes_fragments = set(\n",
    "            sorted(\n",
    "                fragments_df.select(pl.col(\"Chromosome\").unique()).to_series().to_list()\n",
    "            )\n",
    "        )\n",
    "        chromosomes_annotation = set(\n",
    "            annotation_dict[genome_dict[sample]][\"Chromosome\"].unique()\n",
    "        )\n",
    "        chromosomes_common = chromosomes_fragments.intersection(chromosomes_fragments)\n",
    "        chromosomes_unique = chromosomes_fragments.symmetric_difference(\n",
    "            chromosomes_annotation\n",
    "        )\n",
    "        chromosome_counts = (\n",
    "            fragments_df.groupby(\"Chromosome\").count().sort(by=\"count\", descending=True)\n",
    "        )\n",
    "\n",
    "        if verbose:\n",
    "            print(\n",
    "                f\"printing common chromosomes between sample {sample} fragments and {genome_dict[sample]} annotation\"\n",
    "            )\n",
    "            print(\"\\n\")\n",
    "            print(chromosomes_common)\n",
    "            print(\"\\n\")\n",
    "            print(\n",
    "                f\"printing symmetric difference chromosomes between sample {sample} fragments and {genome_dict[sample]} annotation\"\n",
    "            )\n",
    "            print(\"\\n\")\n",
    "            print(chromosomes_unique)\n",
    "            print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f25d40-ba08-4bd6-a123-fd97a4d15086",
   "metadata": {},
   "source": [
    "If the chromosomes between fragments and annotation (or further down regions) do not match, the following code won't work. The easiest way to resolve these problems is to modify the genome annotation so that chromosome names match. Changing the fragments files is not recommended, because then you will have a mismatch between the fragments files and your original genome index + bam files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b915795a-37b5-4d07-a13d-a616839f82ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-14T14:23:19.226009Z",
     "iopub.status.busy": "2023-04-14T14:23:19.225626Z",
     "iopub.status.idle": "2023-04-14T14:23:19.229760Z",
     "shell.execute_reply": "2023-04-14T14:23:19.228806Z",
     "shell.execute_reply.started": "2023-04-14T14:23:19.225985Z"
    }
   },
   "source": [
    "### Define which regions to use to calculate fraction of reads in peaks\n",
    "Ideally this should be cluster consensus peaks called on each sample individually, but for rough QC purposes, the ENCODE SCREEN regions suffice.  \n",
    "We host a copy of these regions for mm10 and hg38 here https://resources.aertslab.org/papers/PUMATAC/PUMATAC_dependencies/regions/. For dm6, you can use the cisTarget regions: https://resources.aertslab.org/cistarget/regions/dm6__regulatory_regions.regionid-location.bed.  \n",
    "\n",
    "If you want to use other regions, please add the path and the corresponding genome name as a value-key pair in `regions_path_dict` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b447a9-84db-442e-a160-b55748654b43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "regions_path_dict = {\n",
    "    \"hg38\": \"PUMATAC_dependencies/regions/V2.hg38-rDHS-Unfiltered.blacklisted.bed\",\n",
    "    \"mm10\": \"PUMATAC_dependencies/regions/V2.mm10-rDHS-Unfiltered.blacklisted.bed\",\n",
    "    \"dm6\": \"PUMATAC_dependencies/regions/dm6__regulatory_regions.regionid-location.bed\",\n",
    "    \"GRCh38_mm10\": \"PUMATAC_dependencies/regions/V2.hg38_mm10-rDHS-Unfiltered.blacklisted.bed\",\n",
    "}\n",
    "regions_path_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7164c478-181f-4167-a784-8e4ac6ecc1f2",
   "metadata": {},
   "source": [
    "Again, if you want, you can manually edit this dictionary and substitute your own regions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51dce57c-8d16-42ad-af33-faa2501fe154",
   "metadata": {},
   "source": [
    "### Run cisTopic quality control tools\n",
    "cisTopic has a suite of functions which calculate per-barcode quality metrics such as number of (unique) fragments, TSS enrichment, fraction of fragments in peaks and so on. Make a directory for cisTopic output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f722d12-d433-4a9d-ab51-789102385f35",
   "metadata": {
    "papermill": {
     "duration": 0.010994,
     "end_time": "2022-09-16T16:02:24.139883",
     "exception": false,
     "start_time": "2022-09-16T16:02:24.128889",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cistopic_qc_out = \"cistopic_qc_out\"\n",
    "if not os.path.exists(cistopic_qc_out):\n",
    "    os.makedirs(cistopic_qc_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76aaf72f-a3cc-4398-8ecf-a2c17be2f556",
   "metadata": {},
   "source": [
    "Determine which fragments files have already gone through cisTopic QC (in case you ran this notebook before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e750d59c-1332-4f80-8d62-d177a609e44f",
   "metadata": {
    "papermill": {
     "duration": 0.027707,
     "end_time": "2022-09-16T16:02:24.172368",
     "exception": false,
     "start_time": "2022-09-16T16:02:24.144661",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "samples_todo = []\n",
    "for sample in samples:\n",
    "    metadata_file = os.path.join(cistopic_qc_out, sample + \"__metadata_bc.pkl\")\n",
    "    print(f\"Checking if {metadata_file} exist...\")\n",
    "    if os.path.exists(metadata_file):\n",
    "        print(\"\\tMetadata exists! Skipping...\")\n",
    "    else:\n",
    "        samples_todo.append(sample)\n",
    "        print(\"\\tMetadata does not exist, adding to subdict to generate\")\n",
    "\n",
    "samples_todo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbdafd9-1e55-4878-9b77-6e8ab50a5bb7",
   "metadata": {},
   "source": [
    "Sort the `samples_todo` by size to slightly increase efficiency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba86f73-4887-421d-a41e-b234c45a9c62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a list of tuples where each tuple contains (sample_name, file_size)\n",
    "samples_sizes = [\n",
    "    (sample, os.path.getsize(fragments_path_dict[sample])) for sample in samples_todo\n",
    "]\n",
    "\n",
    "samples_sizes_sorted = sorted(samples_sizes, key=lambda x: x[1], reverse=True)\n",
    "samples_todo = [sample for sample, _ in samples_sizes_sorted]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db68423d-d0c3-4343-87ae-a1be3f4c0dbe",
   "metadata": {},
   "source": [
    "Then execute cisTopic. The following code will run pycisTopic's QC toolbox on the fragments files provided above. It does so in blocks, where the number of samples per block is defined by `n_cores`. For example, if you have 64 samples, and you define `n_cores = 8`, the following loop will call ray 8 times and run 8 samples each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15104322-85cf-4a6a-be88-0ca5df85352c",
   "metadata": {
    "papermill": {
     "duration": 0.009728,
     "end_time": "2022-09-16T16:02:24.203717",
     "exception": false,
     "start_time": "2022-09-16T16:02:24.193989",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0110a0b-3baa-40c0-a296-80e95d8284b6",
   "metadata": {
    "papermill": {
     "duration": 752.884288,
     "end_time": "2022-09-16T16:14:57.092887",
     "exception": false,
     "start_time": "2022-09-16T16:02:24.208599",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_cores = 8\n",
    "for genome, inverse_genome_dict_samples in inverse_genome_dict.items():\n",
    "    if samples_todo != []:\n",
    "        samples_sub = list(set(samples_todo).intersection(inverse_genome_dict_samples))\n",
    "        blocks = [\n",
    "            samples_sub[i : i + n_cores] for i in range(0, len(samples_sub), n_cores)\n",
    "        ]\n",
    "        pp.pprint(blocks)\n",
    "        for samples_torun_in_block in blocks:\n",
    "            fragments_sub_dict_block = {\n",
    "                key: fragments_path_dict[key] for key in samples_torun_in_block\n",
    "            }\n",
    "            regions_sub_dict_block = {\n",
    "                key: regions_path_dict[genome_dict[key]]\n",
    "                for key in samples_torun_in_block\n",
    "            }\n",
    "            print(f\"Running samples {samples_torun_in_block} for genome {genome}\")\n",
    "\n",
    "            metadata_bc_dict, profile_data_dict = compute_qc_stats(\n",
    "                fragments_dict=fragments_sub_dict_block,\n",
    "                tss_annotation=annotation_dict[genome],\n",
    "                stats=[\n",
    "                    \"barcode_rank_plot\",\n",
    "                    \"duplicate_rate\",\n",
    "                    \"insert_size_distribution\",\n",
    "                    \"profile_tss\",\n",
    "                    \"frip\",\n",
    "                ],\n",
    "                label_list=None,\n",
    "                path_to_regions=regions_sub_dict_block,\n",
    "                n_cpu=n_cores,\n",
    "                valid_bc=None,\n",
    "                n_frag=1,\n",
    "                n_bc=None,\n",
    "                tss_flank_window=2000,\n",
    "                tss_window=50,\n",
    "                tss_minimum_signal_window=100,\n",
    "                tss_rolling_window=10,\n",
    "                # min_norm=0.2,\n",
    "                remove_duplicates=True,\n",
    "            )\n",
    "\n",
    "            ray.shutdown()\n",
    "            print(f\"Done, writing files to {cistopic_qc_out}...\")\n",
    "            for sample in samples:\n",
    "                metadata_bc_dict[sample][\"sample_id\"] = sample\n",
    "                metadata_bc_dict[sample].index = [\n",
    "                    x + \"___\" + sample for x in list(metadata_bc_dict[sample].index)\n",
    "                ]\n",
    "                with open(\n",
    "                    os.path.join(cistopic_qc_out, f\"{sample}__metadata_bc.pkl\"), \"wb\"\n",
    "                ) as f:\n",
    "                    pickle.dump(metadata_bc_dict[sample], f, protocol=4)\n",
    "\n",
    "                with open(\n",
    "                    os.path.join(cistopic_qc_out, f\"{sample}__profile_data.pkl\"), \"wb\"\n",
    "                ) as f:\n",
    "                    pickle.dump(profile_data_dict[sample], f, protocol=4)\n",
    "    else:\n",
    "        print(f\"All samples already processed  for genome {genome}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fd30d2-1008-4571-a813-91de91e98ac3",
   "metadata": {},
   "source": [
    "We have now calculated various QC metrics and can proceed. `{sample}__metadata_bc.pkl` contains barcode level quality metrics such as number of fragments, TSS enrichment, ... per barcode. `__profile_data.pkl` contains the aggregate accessibility profile around TSS for every barcode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61635f7-c8e7-4d21-a821-7273041a0a31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sorted(os.listdir(cistopic_qc_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885ad443-23cd-4fb4-a532-11a1d790af29",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Filter cells from background noise\n",
    "We then filter true cells (high TSS enrichment, and high number of unique fragments in peaks). We will apply Otsu's algorithm on all cells with more than `standard_min_x_val` fragments and a higher than `standard_min_y_val` TSS enrichment. For some samples, the standard minimum values might not produce good results, so these can be edited here if you want. For high quality samples, the standard values should work nicely. By default, Otsu's algorithm is applied to all cell barcodes with more than 100 barcodes and a TSS enrichment of 1. For most (high quality) samples, this works well. However, for some samples, especially samples with a high amount of low-quality barcodes, a higher threshold may be necessary. This can be done using the following dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd90701-f891-40d0-86d1-7f143fbd8fcd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metadata_bc_pkl_path_dict = {\n",
    "    os.path.basename(x).split(\"__metadata_bc.pkl\")[0]: x\n",
    "    for x in sorted(glob.glob(f\"{cistopic_qc_out}/*metadata_bc.pkl\"))\n",
    "}\n",
    "metadata_bc_pkl_path_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c70568e-94b9-4fc4-81d0-9f09ad7557b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "standard_min_x_val = 100\n",
    "standard_min_y_val = 1\n",
    "\n",
    "min_otsu_frags_dict = {}\n",
    "min_otsu_tss_dict = {}\n",
    "\n",
    "for sample in samples:\n",
    "    min_otsu_frags_dict[sample] = standard_min_x_val\n",
    "    min_otsu_tss_dict[sample] = standard_min_y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa7a3d1-f6c8-4816-bc71-f5cdbb95befb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pp.pprint(min_otsu_frags_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a074c2b-8526-4147-822b-bcb09945e0bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pp.pprint(min_otsu_tss_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6c1d30-eec0-4ae7-8ac8-37d335a13b47",
   "metadata": {},
   "source": [
    "And here we actually call Otsu filtering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57ec57d-e24e-45c6-9057-09014bfa18b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(\"selected_barcodes\"):\n",
    "    os.mkdir(\"selected_barcodes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609e730f-c0e3-4c20-bbf2-b2fe4b62a9ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_threshold_dict = {}\n",
    "y_threshold_dict = {}\n",
    "bc_dict = {}\n",
    "n_bc_dict = {}\n",
    "\n",
    "for sample in samples:\n",
    "    with open(metadata_bc_pkl_path_dict[sample], \"rb\") as fh:\n",
    "        metadata_bc_df = pickle.load(fh)\n",
    "\n",
    "    x_arr = np.log10(metadata_bc_df[\"Unique_nr_frag_in_regions\"])\n",
    "    x_threshold_log = pum.threshold_otsu(\n",
    "        x_arr, nbins=5000, min_value=np.log10(min_otsu_frags_dict[sample])\n",
    "    )\n",
    "    x_threshold = 10**x_threshold_log\n",
    "    x_threshold_dict[sample] = x_threshold\n",
    "\n",
    "    y_arr = metadata_bc_df[\"TSS_enrichment\"]\n",
    "    y_threshold = pum.threshold_otsu(\n",
    "        y_arr, nbins=5000, min_value=min_otsu_tss_dict[sample]\n",
    "    )\n",
    "    y_threshold_dict[sample] = y_threshold\n",
    "\n",
    "    # calculate cells passing filter\n",
    "    metadata_bc_df_passing_filters = metadata_bc_df.loc[\n",
    "        (metadata_bc_df.Unique_nr_frag_in_regions > x_threshold)\n",
    "        & (metadata_bc_df.TSS_enrichment > y_threshold)\n",
    "    ]\n",
    "    bc_passing_filters = metadata_bc_df_passing_filters.index\n",
    "    bc_dict[sample] = bc_passing_filters\n",
    "    n_bc_dict[sample] = len(bc_passing_filters)\n",
    "\n",
    "    print(f\"\\tSaving...\")\n",
    "    with open(f\"selected_barcodes/{sample}_bc_passing_filters_otsu.pkl\", \"wb\") as fh:\n",
    "        pickle.dump(bc_passing_filters, fh)\n",
    "    fh.close()\n",
    "\n",
    "    fh = open(f\"selected_barcodes/{sample}_bc_passing_filters_otsu.txt\", \"w\")\n",
    "    for bc in list(bc_passing_filters):\n",
    "        fh.write(bc + \"\\n\")\n",
    "    fh.close()\n",
    "\n",
    "    metadata_bc_df.loc[bc_passing_filters].to_csv(\n",
    "        f\"selected_barcodes/{sample}_metadata_bc_df.tsv\", sep=\"\\t\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04944a59-2bde-43f9-a1a4-d428b7714ad4",
   "metadata": {},
   "source": [
    "We got the following thresholds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0913fd-c14c-4611-b5e8-27091798f938",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pp.pprint(x_threshold_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d877996c-69ee-42e9-af76-626a3b1fddbf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pp.pprint(y_threshold_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838a503e-0902-409e-aa36-bbfc8d0a81e2",
   "metadata": {},
   "source": [
    "## Plotting the results\n",
    "### Calculate KDE using multithreading\n",
    "Multithreading cannot work in current versions of jupyter notebooks due to technicalities. KDE calculation takes a lot of time for large numbers of barcodes. As a workaround, we call a small python script in terminal that will calculate the KDE between log(number of unique fragments in peaks) and the three variables FRIP, TSS enrichment and duplication rate using multithreading outside of the jupyter environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f6673b-148a-494a-baa9-a02a5f648891",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(\"plots_qc\"):\n",
    "    os.mkdir(\"plots_qc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442801e8-f2c2-4ca9-b917-6397a696b49d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_cores = 8\n",
    "\n",
    "mounts = \"/dev/sda1,/home,/home/florianderop/tmp:/tmp\"\n",
    "sif = \"/home/florianderop/data/PUMATAC_dependencies/jupyter_kernels/20230504_pycistopic.sif\"\n",
    "script = \"scripts/multithread_kde.py\"\n",
    "\n",
    "for sample in samples:\n",
    "    cmd = f\"echo {sample} && singularity exec -B {mounts} {sif} python {script} -i {metadata_bc_pkl_path_dict[sample]} -c {n_cores} &\"\n",
    "\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0570fd88-ac18-47ed-8b89-23b7e8a8052c",
   "metadata": {},
   "source": [
    "We determine `xlim` and `ylim` based on global minima and maxima. In this way, all plots will have the same limits and can thus be compared more easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69543b6-d46d-4182-bceb-b714571c63cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metadata_bc_df_all = pd.DataFrame()\n",
    "for sample in samples:\n",
    "    with open(metadata_bc_pkl_path_dict[sample], \"rb\") as fh:\n",
    "        metadata_bc_df = pickle.load(fh)\n",
    "        metadata_bc_df_all = pd.concat([metadata_bc_df_all, metadata_bc_df])\n",
    "        print(f\"Added {sample} metadata_bc_df\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362c82f9-b81b-4099-80f2-1fbc24ac9b18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-14T15:37:27.319296Z",
     "iopub.status.busy": "2023-04-14T15:37:27.318948Z",
     "iopub.status.idle": "2023-04-14T15:37:27.324654Z",
     "shell.execute_reply": "2023-04-14T15:37:27.323940Z",
     "shell.execute_reply.started": "2023-04-14T15:37:27.319274Z"
    }
   },
   "source": [
    "Calculate global maxima for variables, will be used to scale plots later. The idea is that plots for different samples will have the same axis limits so they can be compared directly visually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf384c3-1d2d-437f-ab6d-c97846c693eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_dict = {}\n",
    "min_dict = {}\n",
    "for stat in metadata_bc_df_all.columns:\n",
    "    max_dict[stat] = metadata_bc_df_all[stat].max()\n",
    "    min_dict[stat] = metadata_bc_df_all[stat].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088c81f9-243d-49b8-82d9-fede1a2852de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pp.pprint(min_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5a44ec-bb6c-49f7-a8a6-2f177afe7cca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pp.pprint(max_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9905cf7-e9a1-495e-8827-a00b77e555f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-14T15:40:26.342791Z",
     "iopub.status.busy": "2023-04-14T15:40:26.342412Z",
     "iopub.status.idle": "2023-04-14T15:40:26.348301Z",
     "shell.execute_reply": "2023-04-14T15:40:26.347588Z",
     "shell.execute_reply.started": "2023-04-14T15:40:26.342767Z"
    }
   },
   "source": [
    "Finally, we plot. Boolean `kde` determines whether kernel density will be displayed on the plots as color. If `kde` = True, then the script will first check whether or not the KDE columns`kde__log_{x_var}__{y_var}` exists in the metadata_bc dataframe (computed in the previous cell). If this column does not exist, then it will be calculated in this notebook WITHOUT multithreading. This can take a long time to compute for many barcodes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3379b68b-c30a-4824-8b32-34ebcdf38127",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kde = True\n",
    "overwrite = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfc544c-0bd2-4db3-9afe-a8adee6c7824",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for sample in samples:\n",
    "    out_path = f\"plots_qc/{sample}_qc_otsu.png\"\n",
    "    if overwrite == False and os.path.exists(out_path):\n",
    "        print(f\"{out_path} exists, skipping...\")\n",
    "        display(Image(filename=out_path))\n",
    "\n",
    "    else:\n",
    "        print(f\"{out_path} does not exist yet, generating...\")\n",
    "        print(f\"\\tLoading {metadata_bc_pkl_path_dict[sample]}\")\n",
    "\n",
    "        fig = pum.plot_qc(\n",
    "            sample=sample,\n",
    "            sample_alias=alias_dict[sample],\n",
    "            bc_passing_filters=bc_dict[sample],\n",
    "            x_thresh=x_threshold_dict[sample],\n",
    "            y_thresh=y_threshold_dict[sample],\n",
    "            metadata_bc_pkl_path=metadata_bc_pkl_path_dict[sample],\n",
    "            max_dict=max_dict,\n",
    "            min_dict=min_dict,\n",
    "            include_kde=kde,\n",
    "        )\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(out_path, dpi=300, facecolor=\"white\")\n",
    "        plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22b60a7-6f2f-42ad-89c0-6a0757aa4b4b",
   "metadata": {},
   "source": [
    "### Custom thresholds for cell calling\n",
    "If you're not happy with the Otsu thresholds, you can also specify your own thresholds here and replot (and re-write selected barcodes if `overwrite` is set to True:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c780de77-9d21-4c53-8868-f6d258fdb32e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "overwrite = False  # whether or not to overwrite the Otsu picked barcode thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a4e959-30fc-460c-b8be-00bafa2c4d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_threshold_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5121c85-c412-49fa-82d5-3da0a7492350",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_threshold_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194e035a-4164-40b3-971b-cb4333f0dce8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if overwrite == True:\n",
    "    x_threshold_dict = {\"x1284_4\": 1074.4946893830286, \"x1284_8\": 908.048695705127}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c43f391-16ca-4a88-86b0-79570f2c4a35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if overwrite == True:\n",
    "    y_threshold_dict = {\"x1284_4\": 12.162766645451292, \"x1284_8\": 11.706190038078017}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3db3d4e-a8e1-4699-9502-1180a1e87393",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if overwrite == True:\n",
    "    bc_dict = {}\n",
    "    n_bc_dict = {}\n",
    "\n",
    "    for sample in samples:\n",
    "        with open(metadata_bc_pkl_path_dict[sample], \"rb\") as fh:\n",
    "            metadata_bc_df = pickle.load(fh)\n",
    "\n",
    "        # calculate cells passing filter\n",
    "        x_threshold = x_threshold_dict[sample]\n",
    "        y_threshold = y_threshold_dict[sample]\n",
    "\n",
    "        metadata_bc_df_passing_filters = metadata_bc_df.loc[\n",
    "            (metadata_bc_df.Unique_nr_frag_in_regions > x_threshold)\n",
    "            & (metadata_bc_df.TSS_enrichment > y_threshold)\n",
    "        ]\n",
    "        bc_passing_filters = metadata_bc_df_passing_filters.index\n",
    "        bc_dict[sample] = bc_passing_filters\n",
    "        n_bc_dict[sample] = len(bc_passing_filters)\n",
    "\n",
    "        print(f\"\\tSaving...\")\n",
    "        with open(\n",
    "            f\"selected_barcodes/{sample}_bc_passing_filters_otsu.pkl\", \"wb\"\n",
    "        ) as fh:\n",
    "            pickle.dump(bc_passing_filters, fh)\n",
    "        fh.close()\n",
    "\n",
    "        fh = open(f\"selected_barcodes/{sample}_bc_passing_filters_otsu.txt\", \"w\")\n",
    "        for bc in list(bc_passing_filters):\n",
    "            fh.write(bc + \"\\n\")\n",
    "        fh.close()\n",
    "\n",
    "        metadata_bc_df.loc[bc_passing_filters].to_csv(\n",
    "            f\"selected_barcodes/{sample}_metadata_bc_df.tsv\", sep=\"\\t\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c818de03-ea88-4fe1-a5cc-db49dbf977f8",
   "metadata": {},
   "source": [
    "Then, if you like, you can re-make the QC plots with your new thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a65e012-3a56-4a26-8f53-a9dfb86c6a0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if overwrite == True:\n",
    "    for sample in samples:\n",
    "        print(f\"{out_path} does not exist yet, generating...\")\n",
    "        print(f\"\\tLoading {metadata_bc_pkl_path_dict[sample]}\")\n",
    "        with open(metadata_bc_pkl_path_dict[sample], \"rb\") as fh:\n",
    "            metadata_bc_df = pickle.load(fh)\n",
    "\n",
    "        fig = pum.plot_qc(\n",
    "            sample=sample,\n",
    "            sample_alias=alias_dict[sample],\n",
    "            bc_passing_filters=bc_dict[sample],\n",
    "            x_thresh=x_threshold_dict[sample],\n",
    "            y_thresh=y_threshold_dict[sample],\n",
    "            metadata_bc_pkl_path=metadata_bc_pkl_path_dict[sample],\n",
    "            max_dict=max_dict,\n",
    "            min_dict=min_dict,\n",
    "            include_kde=kde,\n",
    "        )\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(out_path, dpi=300, facecolor=\"white\")\n",
    "        plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f1d2f4-438c-4ec7-ad34-4f3c2bafa4ca",
   "metadata": {},
   "source": [
    "## Plot combined figures\n",
    "Now, we can combine all QC plots into one plot per variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d137bbf3-3cf0-4c59-a670-89a0706b41ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_cols = 3\n",
    "n_rows = math.ceil(len(samples) / n_cols)\n",
    "figheight = n_rows * 3\n",
    "figwidth = n_cols * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b7d9db-aeb3-487e-89f9-c3b0198f1925",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_var = \"Unique_nr_frag_in_regions\"\n",
    "y_var = \"TSS_enrichment\"\n",
    "x_label = \"Unique nr frag in regions\"\n",
    "y_label = \"TSS enrichment\"\n",
    "\n",
    "pum.qc_mega_plot(\n",
    "    metadata_bc_pkl_path_dict=metadata_bc_pkl_path_dict,\n",
    "    sample_order=samples,\n",
    "    include_kde=True,\n",
    "    x_var=x_var,\n",
    "    y_var=y_var,\n",
    "    x_label=x_label,\n",
    "    y_label=y_label,\n",
    "    x_threshold_dict=x_threshold_dict,\n",
    "    y_threshold_dict=y_threshold_dict,\n",
    "    min_dict=min_dict,\n",
    "    max_dict=max_dict,\n",
    "    alias_dict=alias_dict,\n",
    "    n_cols=n_cols,\n",
    "    figheight=figheight,\n",
    "    figwidth=figwidth,\n",
    ")\n",
    "\n",
    "plt.savefig(f\"plots_qc/all_{x_var}__{y_var}.png\", dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ece97b-57a2-4d33-bf80-634fc78fce35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_var = \"Unique_nr_frag_in_regions\"\n",
    "y_var = \"FRIP\"\n",
    "x_label = \"Unique nr frag in regions\"\n",
    "y_label = \"FRIP\"\n",
    "\n",
    "pum.qc_mega_plot(\n",
    "    metadata_bc_pkl_path_dict=metadata_bc_pkl_path_dict,\n",
    "    sample_order=samples,\n",
    "    include_kde=True,\n",
    "    x_var=x_var,\n",
    "    y_var=y_var,\n",
    "    x_label=x_label,\n",
    "    y_label=y_label,\n",
    "    x_threshold_dict=x_threshold_dict,\n",
    "    y_threshold_dict=y_threshold_dict,\n",
    "    min_dict=min_dict,\n",
    "    max_dict=max_dict,\n",
    "    alias_dict=alias_dict,\n",
    "    n_cols=n_cols,\n",
    "    figheight=figheight,\n",
    "    figwidth=figwidth,\n",
    ")\n",
    "\n",
    "plt.savefig(f\"plots_qc/all_{x_var}__{y_var}.png\", dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a026739-1dee-4373-bf43-4c985e4b7f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_var = \"Unique_nr_frag_in_regions\"\n",
    "y_var = \"Dupl_rate\"\n",
    "x_label = \"Unique nr frag in regions\"\n",
    "y_label = \"Duplicate rate\"\n",
    "\n",
    "pum.qc_mega_plot(\n",
    "    metadata_bc_pkl_path_dict=metadata_bc_pkl_path_dict,\n",
    "    sample_order=samples,\n",
    "    include_kde=True,\n",
    "    x_var=x_var,\n",
    "    y_var=y_var,\n",
    "    x_label=x_label,\n",
    "    y_label=y_label,\n",
    "    x_threshold_dict=x_threshold_dict,\n",
    "    y_threshold_dict=y_threshold_dict,\n",
    "    min_dict=min_dict,\n",
    "    max_dict=max_dict,\n",
    "    alias_dict=alias_dict,\n",
    "    n_cols=n_cols,\n",
    "    figheight=figheight,\n",
    "    figwidth=figwidth,\n",
    ")\n",
    "\n",
    "plt.savefig(f\"plots_qc/all_{x_var}__{y_var}.png\", dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36a864e-7777-48ae-85f6-4789e5830d1a",
   "metadata": {},
   "source": [
    "# Plot profile data\n",
    "The following plots deal with the average accessibility profiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d66d1e-6fa9-47b5-925b-68b9f7126d9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "profile_data_pkl_path_dict = {\n",
    "    os.path.basename(x).split(\"__profile_data.pkl\")[0]: x\n",
    "    for x in sorted(glob.glob(f\"{cistopic_qc_out}/*__profile_data.pkl\"))\n",
    "}\n",
    "profile_data_pkl_path_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4eb21c-74a8-4faa-aa38-af8c50bb961a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "profile_data_dict_dict = {}\n",
    "if not os.path.exists(f\"plots_qc/all_profile_metrics.png\"):\n",
    "    for sample in samples:\n",
    "        path = profile_data_pkl_path_dict[sample]\n",
    "\n",
    "        with open(path, \"rb\") as fh:\n",
    "            profile_data_dict = pickle.load(fh)\n",
    "        profile_data_dict_dict[sample] = profile_data_dict\n",
    "\n",
    "    plot_sample_metrics(\n",
    "        {\n",
    "            alias_dict[x]: profile_data_dict_dict[x]\n",
    "            for x in profile_data_dict_dict.keys()\n",
    "        },\n",
    "        ncol=3,\n",
    "        plot=True,\n",
    "        profile_list=[\n",
    "            \"barcode_rank_plot\",\n",
    "            \"insert_size_distribution\",\n",
    "            \"profile_tss\",\n",
    "        ],\n",
    "        insert_size_distriubtion_xlim=[0, 1000],\n",
    "    )\n",
    "    plt.savefig(\n",
    "        fname=f\"plots_qc/all_profile_metrics.png\",\n",
    "        dpi=300,\n",
    "        bbox_inches=\"tight\",\n",
    "        facecolor=\"white\",\n",
    "    )\n",
    "    plt.show()\n",
    "else:\n",
    "    display(Image(filename=f\"plots_qc/all_profile_metrics.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca28f105-0dcd-44de-bd31-675ddeafab68",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for sample in samples:\n",
    "    if not os.path.exists(f\"plots_qc/{sample}_profile_metrics.png\"):\n",
    "        path = profile_data_dict[sample]\n",
    "        with open(path, \"rb\") as fh:\n",
    "            profile_data_dict = pickle.load(fh)\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "        plot_sample_metrics(\n",
    "            profile_data_dict,\n",
    "            ncol=3,\n",
    "            plot=True,\n",
    "            profile_list=[\n",
    "                \"barcode_rank_plot\",\n",
    "                \"insert_size_distribution\",\n",
    "                \"profile_tss\",\n",
    "            ],\n",
    "            insert_size_distriubtion_xlim=[0, 1000],\n",
    "        )\n",
    "        plt.suptitle(alias_dict[sample])\n",
    "        plt.savefig(\n",
    "            fname=f\"plots_qc/{sample}_profile_metrics.png\",\n",
    "            dpi=300,\n",
    "            bbox_inches=\"tight\",\n",
    "            facecolor=\"white\",\n",
    "        )\n",
    "        plt.show()\n",
    "    else:\n",
    "        display(Image(filename=f\"plots_qc/{sample}_profile_metrics.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da27c5b3-d69a-46ce-b2fe-fed3189f917f",
   "metadata": {},
   "source": [
    "# 2. Gather QC stats from pipeline output and cisTopic\n",
    "No need to read this, we are parsing information needed to make the plots below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0986883-ecd8-4b47-9fce-6eceebe8c539",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fragments_path_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6542b68d-6188-4a13-9c42-8a9b35709f80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_barcodes_path_dict = {\n",
    "    os.path.basename(x).split(\"_bc_passing_filters_otsu.txt\")[0]: x\n",
    "    for x in glob.glob(\"selected_barcodes/*_bc_passing_filters_otsu.txt\")\n",
    "}\n",
    "selected_barcodes_path_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2562215b-3e89-441a-a184-01e5908e63d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(pum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e19a77e-cc39-4fbb-8dc0-8a3157de49ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_stats = pum.scrape_mapping_stats(\n",
    "    pumatac_output_dir=pumatac_output_dir,\n",
    "    cr_output_dir=cr_output_dir,\n",
    "    selected_barcodes_path_dict=selected_barcodes_path_dict,\n",
    "    pipeline_dict=pipeline_dict,\n",
    "    verbose=True,\n",
    ")\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdc534d-575f-4c4e-8847-f78f480cb1b5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3c. Single-cell level statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c234c50d-7d0a-47f6-85bb-be82c5609bf8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420a387f-3479-47a6-80e6-c7627eb414fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metadata_path_dict = {\n",
    "    x.split(\"/\")[-1].split(f\"__metadata_bc.pkl\")[0]: x\n",
    "    for x in sorted(glob.glob(f\"{cistopic_qc_out}/*metadata*pkl\"))\n",
    "}\n",
    "if verbose:\n",
    "    pp.pprint(metadata_path_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5d4911-0152-42b8-b691-a5ecb535a80d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_cells_path_dict = {\n",
    "    x.split(\"/\")[-1].split(f\"_bc_passing_filters_otsu.pkl\")[0]: x\n",
    "    for x in sorted(glob.glob(f\"selected_barcodes/*.pkl\"))\n",
    "}\n",
    "if verbose:\n",
    "    pp.pprint(selected_cells_path_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ebaacf-0189-48ef-82db-c9d625cdf1a4",
   "metadata": {},
   "source": [
    "Read the cisTopic output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8316d470-d508-45ea-935d-294c351c3067",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_scstats_merged, df_stats = pum.scrape_scstats(\n",
    "    metadata_path_dict, selected_cells_path_dict, df_stats\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5e4c6b-9e69-4b92-b799-779202ca27db",
   "metadata": {},
   "source": [
    "These are variables necessary for plotting (order of samples, color palettes, ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2febef86-cdfc-457c-b2b7-85b0d92aa4fe",
   "metadata": {},
   "source": [
    "Load the reference data from De Rop et al., 2023 and combine it with the user samples:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63e07fa-2f28-4e43-ac89-7a3c13716dfc",
   "metadata": {},
   "source": [
    "### 3d. Sequencing efficiency statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fc9ca9-295c-4673-834f-3771a03bde30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_stats_merged = pum.calculate_losses(df_stats, df_scstats_merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be731aba-89ed-4f93-97c9-2733e367fa73",
   "metadata": {},
   "source": [
    "# 3. Plot and compare to De Rop et al., 2023 benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba05bdc-926a-4e35-a81d-747f9ab4c4e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.set_context(\"notebook\")\n",
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af07d36f-2f4e-4922-99d1-bb581590bcfb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-24T09:56:35.311915Z",
     "iopub.status.busy": "2023-04-24T09:56:35.311531Z",
     "iopub.status.idle": "2023-04-24T09:56:35.317437Z",
     "shell.execute_reply": "2023-04-24T09:56:35.316693Z",
     "shell.execute_reply.started": "2023-04-24T09:56:35.311891Z"
    },
    "tags": []
   },
   "source": [
    "If you want, you can change the order in which your samples are plotted by manually editing key `user_sample` in the dictionary `order_dict_tech_ultrashort`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6f9a3a-fe39-4d8d-ac3e-0832fe27ad5f",
   "metadata": {},
   "source": [
    "Some variables necessary for plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d15185-9ebf-44f9-b6a3-b04926fc1e92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "order = [\n",
    "    \"tech\",\n",
    "    \"No correct barcode\",\n",
    "    \"Not mapped properly\",\n",
    "    \"Fragments in noise barcodes\",\n",
    "    \"Duplicate fragments in cells\",\n",
    "    \"Unique, in cells, not in peaks\",\n",
    "    \"Unique, in cells, in peaks\",\n",
    "]\n",
    "\n",
    "order = order[::-1]\n",
    "\n",
    "losses_color_palette = palettable.cartocolors.qualitative.Safe_7.get_mpl_colormap()\n",
    "\n",
    "tech_alias_dict = {\n",
    "    \"10xmultiome\": \"10x\\nMultiome\",\n",
    "    \"10xv1\": \"10x v1\",\n",
    "    \"10xv11\": \"10x v1.1\",\n",
    "    \"10xv11c\": \"10x v1.1\\ncontrols\",\n",
    "    \"10xv2\": \"10x v2\",\n",
    "    \"ddseq\": \"Bio-Rad\\nddSEQ SureCell\",\n",
    "    \"hydrop\": \"HyDrop\",\n",
    "    \"mtscatac\": \"mtscATAC-seq\",\n",
    "    \"mtscatacfacs\": \"*\",\n",
    "    \"s3atac\": \"s3-ATAC\",\n",
    "    \"user_sample\": \"User samples\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c91a5b-0cc2-4ec8-9ee3-285e2695d6b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T15:26:11.785141Z",
     "iopub.status.busy": "2023-04-21T15:26:11.784749Z",
     "iopub.status.idle": "2023-04-21T15:26:11.788471Z",
     "shell.execute_reply": "2023-04-21T15:26:11.787891Z",
     "shell.execute_reply.started": "2023-04-21T15:26:11.785116Z"
    }
   },
   "source": [
    "### 3a. Sequencing efficiency & Single-cell statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea17e36-f881-4abe-a12b-b8f8cc05b9a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "individual_barplot_width = 0.5\n",
    "individual_plot_row_height = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589f2ac3-a33f-4f95-ac61-fd01caf3cb30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tech_order = [\n",
    "    \"10xv1\",\n",
    "    \"10xv11\",\n",
    "    \"10xv11c\",\n",
    "    \"10xv2\",\n",
    "    \"10xmultiome\",\n",
    "    \"user_sample\",\n",
    "    \"mtscatac\",\n",
    "    \"mtscatacfacs\",\n",
    "    \"ddseq\",\n",
    "    \"s3atac\",\n",
    "    \"hydrop\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4742984f-a662-496c-aba6-b9798098c0a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ylim_dict = {\n",
    "    \"Unique_nr_frag_in_regions\": [0, 20000],\n",
    "    \"Unique_nr_frag_in_regions_k\": [0, 20],\n",
    "    \"FRIP\": [0, 1],\n",
    "    \"TSS_enrichment\": [0, 45],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4f48cf-d7aa-412f-a22f-d1cb17552b9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "individual_barplot_width = 0.5\n",
    "individual_plot_row_height = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18969e39-473b-4313-9e85-26bb21b8f830",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "variables_list = [\"Unique_nr_frag_in_regions_k\", \"TSS_enrichment\", \"FRIP\"]\n",
    "\n",
    "pum.plot_all_qc(\n",
    "    df_stats_merged,\n",
    "    df_scstats_merged,\n",
    "    variables_list,\n",
    "    samples,\n",
    "    alias_dict,\n",
    "    tech_order,\n",
    "    ylim_dict,\n",
    "    svg_output_path=\"plots_qc/all_barplots.svg\",\n",
    "    png_output_path=\"plots_qc/all_barplots.png\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c98d31-7e1e-4860-82f3-9a9f166a6f57",
   "metadata": {},
   "source": [
    "Only the user samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1250a14f-2701-4850-a3f6-0a0c6405dfa5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ymax_frags = (\n",
    "    df_scstats_merged[df_scstats_merged[\"tech\"] == \"user_sample\"]\n",
    "    .groupby(\"sample_id\")[\"Unique_nr_frag_in_regions\"]\n",
    "    .median()\n",
    "    .max()\n",
    "    * 2\n",
    ")\n",
    "ymax_frags_k = (\n",
    "    df_scstats_merged[df_scstats_merged[\"tech\"] == \"user_sample\"]\n",
    "    .groupby(\"sample_id\")[\"Unique_nr_frag_in_regions_k\"]\n",
    "    .median()\n",
    "    .max()\n",
    "    * 2\n",
    ")\n",
    "ymax_tss = (\n",
    "    df_scstats_merged[df_scstats_merged[\"tech\"] == \"user_sample\"]\n",
    "    .groupby(\"sample_id\")[\"TSS_enrichment\"]\n",
    "    .median()\n",
    "    .max()\n",
    "    * 2\n",
    ")\n",
    "\n",
    "ylim_dict = {\n",
    "    \"Unique_nr_frag_in_regions\": [0, ymax_frags],\n",
    "    \"Unique_nr_frag_in_regions_k\": [0, ymax_frags_k],\n",
    "    \"FRIP\": [0, 1],\n",
    "    \"TSS_enrichment\": [0, ymax_tss],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb98fc3f-8d4e-4946-b887-ed94ba24e71b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "variables_list = [\"Unique_nr_frag_in_regions_k\", \"TSS_enrichment\", \"FRIP\"]\n",
    "\n",
    "pum.plot_all_qc(\n",
    "    df_stats_merged,\n",
    "    df_scstats_merged,\n",
    "    variables_list,\n",
    "    samples,\n",
    "    alias_dict,\n",
    "    [\"user_sample\"],\n",
    "    ylim_dict,\n",
    "    svg_output_path=\"plots_qc/usersamples_barplots.svg\",\n",
    "    png_output_path=\"plots_qc/usersamples_barplots.png\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ed6bd4-e39a-4fb9-9763-32028ca91567",
   "metadata": {},
   "source": [
    "# 4. Saturation analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a1a46b-a66f-42c4-8516-e1eec0c962d7",
   "metadata": {},
   "source": [
    "The following code subsets the `fragments.tsv.gz` file for selected cells, and then calculates the saturation within these selected cells."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb90381-db24-44ce-9755-fb47f34beefa",
   "metadata": {},
   "source": [
    "First, load the barcodes we filtered as cells. Make sure that the barcodes match the barcodes in the fragments files! Take special care to remove any suffixes or prefixes that you may have added to the barcodes. For example, cisTopic adds `__{sample}` as a suffix to each barcode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef0d742-72f4-4137-aaf1-d9bd1640204a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_barcodes_dict = {}\n",
    "n_cells_dict = {}\n",
    "for filepath in sorted(glob.glob(\"selected_barcodes/*pkl\")):\n",
    "    sample = os.path.basename(filepath).split(\"_bc\")[0]\n",
    "    with open(filepath, \"rb\") as f:\n",
    "        selected_barcodes = list(pickle.load(f))\n",
    "    selected_barcodes = [x.split(\"___\")[0] for x in selected_barcodes]\n",
    "    newfilepath = filepath.replace(\".pkl\", \".RAW.txt\")\n",
    "    with open(newfilepath, \"w\") as fp:\n",
    "        for item in selected_barcodes:\n",
    "            fp.write(\"%s\\n\" % item)\n",
    "\n",
    "    selected_barcodes_dict[sample] = selected_barcodes\n",
    "    n_cells_dict[sample] = len(selected_barcodes)\n",
    "\n",
    "pp.pprint(n_cells_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cb40be-4eac-4aad-af51-88660f5cd9c2",
   "metadata": {},
   "source": [
    "Make a directory where the saturation statistics will be written:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4305dc-c266-42c9-a542-b440d8f1acd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "saturation_stats_path = \"saturation_stats\"\n",
    "if not os.path.exists(saturation_stats_path):\n",
    "    os.mkdir(saturation_stats_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd4490f-fb17-4b78-bebb-286f3eb05817",
   "metadata": {},
   "source": [
    "Check which ones were already run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83121d37-000c-48e2-bbdc-68c2bfd519d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sampling_stats_path_dict = {\n",
    "    x.split(\"/\")[-1].split(\".sampling\")[0]: x\n",
    "    for x in sorted(glob.glob(f\"{saturation_stats_path}/*.sampling_stats.tsv\"))\n",
    "}\n",
    "sampling_stats_path_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c754685e-11ff-45e3-8442-18ee5b36f011",
   "metadata": {},
   "source": [
    "### Calculate the downsampling statistics\n",
    "We will now downsampled the fragments files at set intervals and calculate quality metrics on these downsampled sets. Then, we will use these datapoints to fit a curve and extrapolate further sequencing saturation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a029e91e-9259-4988-804a-de08033ac4ea",
   "metadata": {},
   "source": [
    "Define the sampling fractions (levels to which we will downsample the fragments file and calculate saturation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c49b76-23c0-4d83-ba39-492d494e6076",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sampling_fractions = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 0.97, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7aa6bb1-dd26-42c7-9f85-36369440f584",
   "metadata": {},
   "source": [
    "### Option #1: Execute the downsampling script using singularity\n",
    "This is preferred in case you have many fragments files and want to parallelize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0612ed1-218c-4e9f-8d9d-decad147a92f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "raw_barcode_path = {\n",
    "    os.path.basename(x).split(\"_bc\")[0]: x\n",
    "    for x in sorted(glob.glob(\"selected_barcodes/*RAW.txt\"))\n",
    "}\n",
    "mounts = \"/dev/sda1,/home,/home/florianderop/tmp:/tmp\"\n",
    "sif_path = \"/home/florianderop/data/PUMATAC_dependencies/jupyter_kernels/20230504_pycistopic.sif\"\n",
    "script_path = \"scripts/sub_sample_fragments.py\"\n",
    "\n",
    "for sample in samples:\n",
    "    fragments_path = fragments_path_dict[sample]\n",
    "    if sample not in sampling_stats_path_dict.keys():\n",
    "        command = f\"singularity exec -B {mounts} {sif_path} python {script_path} -i {os.path.abspath(fragments_path)} -o {saturation_stats_path}/{sample} -c {os.path.abspath(raw_barcode_path[sample])} -s {','.join([str(x) for x in sampling_fractions])} -n {int(df_stats.at[sample, 'n_reads'])} &\"\n",
    "\n",
    "        print(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e821dd7f-eaa9-4dfd-922b-ff8a2fb4da83",
   "metadata": {},
   "source": [
    "And call these commands in command line. `&` indicates that the command will be submitted as background job."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0aed4dd-e9ad-4603-a7e7-e7f9752a821f",
   "metadata": {},
   "source": [
    "### Option #2. Run the function directly in this notebook:\n",
    "Fastest method for a few samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6cc511-5c65-4d3f-90d6-f2e1377f3233",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_stats_path_dict = {\n",
    "    x.split(\"/\")[-1].split(\".sampling\")[0]: x\n",
    "    for x in sorted(glob.glob(f\"{saturation_stats_path}/*.sampling_stats.tsv\"))\n",
    "}\n",
    "sampling_stats_path_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c3c010-bc2a-418b-81a8-9189e035e5c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "covar_dict = {}\n",
    "best_fit_ab_dict = {}\n",
    "x_fit_dict = {}\n",
    "y_fit_dict = {}\n",
    "pl.enable_string_cache(True)\n",
    "\n",
    "for sample in samples:\n",
    "    print(sample)\n",
    "\n",
    "    if (not sample in sampling_stats_path_dict.keys()) or (overwrite == True):\n",
    "        print(f\"{sample} stats do not exist\")\n",
    "\n",
    "        frags_path = fragments_path_dict[sample]\n",
    "        fragments_df = pum.read_bc_and_counts_from_fragments_file(frags_path)\n",
    "\n",
    "        # Sub-sample.\n",
    "        stats_df = pum.sub_sample_fragments(\n",
    "            fragments_df=fragments_df,\n",
    "            selected_barcodes=selected_barcodes_dict[sample],\n",
    "            sampling_fractions=sampling_fractions,\n",
    "            stats_tsv_filename=f\"{saturation_stats_path}/{sample}.sampling_stats.tsv\",\n",
    "            # whitelist=args.whitelist,\n",
    "            n_reads=df_stats.at[sample, \"n_reads\"],\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20773563-d73f-41ae-ae24-d1f779551f4e",
   "metadata": {},
   "source": [
    "### Plotting the saturation\n",
    "The following files should be generated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ad5f09-32fa-466f-aaa0-461269e1d703",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sampling_stats_path_dict = {\n",
    "    x.split(\"/\")[-1].split(\".sampling\")[0]: x\n",
    "    for x in sorted(glob.glob(f\"{saturation_stats_path}/*.sampling_stats.tsv\"))\n",
    "}\n",
    "sampling_stats_path_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9d262f-f3d8-4a52-bd4d-8dd27b4351b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-04T16:24:10.415966Z",
     "iopub.status.busy": "2023-05-04T16:24:10.415427Z",
     "iopub.status.idle": "2023-05-04T16:24:10.421752Z",
     "shell.execute_reply": "2023-05-04T16:24:10.420739Z",
     "shell.execute_reply.started": "2023-05-04T16:24:10.415926Z"
    }
   },
   "source": [
    "First, we plot the saturation of median unique fragments per barcode. I also want to find out at which dept I reach 75% of the saturation value (plotted in blue):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705cb755-8d51-4dba-8ab4-e2b0cf531420",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "percentage_toplot = 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32ed821-5817-4f12-8474-8352bf349a0d",
   "metadata": {},
   "source": [
    "On the x-axis, I want to plot the mean reads per barcode (i.e. the total number of sequenced reads divided by the number of cells), on the y-axis I want the median number of unique fragments, and I also want to indicate the current saturation level (i.e. the saturation of the full, non-sampled fragments file)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102ac0f8-125f-4454-a2a1-b3b270046aa2",
   "metadata": {},
   "source": [
    "I use a michaelis-menten kinetic model to fit these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fa747e-7762-4fe8-836e-7ecd670d3952",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def MM(x, Vmax, Km):\n",
    "    \"\"\"\n",
    "    Define the Michaelis-Menten Kinetics model that will be used for the model fitting.\n",
    "    \"\"\"\n",
    "    if Vmax > 0 and Km > 0:\n",
    "        y = (Vmax * x) / (Km + x)\n",
    "    else:\n",
    "        y = 1e10\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ac9303-d948-44ff-a0a3-95fe0b220477",
   "metadata": {},
   "source": [
    "In the following plot, `kRPC` denotes reads per cell (thousands)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fda813a-7046-4da8-aaab-07998fb20462",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.set_style(\"ticks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85855ed9-1f44-4a52-96f5-66a22c509210",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sampling_stats_path_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509ed2b6-7c7d-43c4-b63b-b2effc8925e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for sample in samples:\n",
    "    print(sample)\n",
    "    if (not os.path.exists(f\"plots_qc/{sample}__fragments_saturation.png\")) or (\n",
    "        overwrite == True\n",
    "    ):\n",
    "        pum.plot_saturation_fragments(\n",
    "            sampling_stats_path_dict[sample],\n",
    "            alias_dict[sample],\n",
    "            df_stats.at[sample, \"n_reads\"],\n",
    "            df_stats.at[sample, \"n_cells\"],\n",
    "            x_axis=\"mean_reads_per_barcode\",\n",
    "            y_axis=\"median_uniq_frag_per_bc\",\n",
    "            function=MM,\n",
    "            percentage_toplot=percentage_toplot,\n",
    "            plot_current_saturation=True,\n",
    "            svg_output_path=f\"plots_qc/{sample}__fragments_saturation.svg\",\n",
    "            png_output_path=f\"plots_qc/{sample}__fragments_saturation.png\",\n",
    "        )\n",
    "    else:\n",
    "        display(\n",
    "            Image(filename=f\"plots_qc/{sample}__fragments_saturation.png\", width=600)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907d1395-ba41-45b9-80df-fb5fc621e628",
   "metadata": {},
   "source": [
    "Now, I want the duplication rate (fraction of fragments that are duplicates) on the y-axis instead. I also want to find the depth where 75% of reads are duplicates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3cae4b-88b4-4fef-8926-90f88ff731b1",
   "metadata": {},
   "source": [
    "I use a michaelis-menten kinetic model with a maximum value fixed to 1 (number of duplicates cannot exceed 100%) to fit these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d315da3-59ac-44c4-bbc8-5495286e7238",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def MM_duplication(x, Km):\n",
    "    \"\"\"\n",
    "    Define the Michaelis-Menten Kinetics model that will be used for the model fitting.\n",
    "    \"\"\"\n",
    "    if Km > 0:\n",
    "        y = x / (Km + x)\n",
    "    else:\n",
    "        y = 1e10\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1692fd54-a9d7-418e-8bd6-69f5d1857a01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for sample in samples:\n",
    "    print(sample)\n",
    "    filepath = sampling_stats_path_dict[sample]\n",
    "    n_reads = df_stats.at[sample, \"n_reads\"]\n",
    "    if (not os.path.exists(f\"plots_qc/{sample}__duplication_saturation.png\")) or (\n",
    "        overwrite == True\n",
    "    ):\n",
    "        pum.plot_saturation_duplication(\n",
    "            sampling_stats_path_dict[sample],\n",
    "            alias_dict[sample],\n",
    "            df_stats.at[sample, \"n_reads\"],\n",
    "            df_stats.at[sample, \"n_cells\"],\n",
    "            x_axis=\"mean_reads_per_barcode\",\n",
    "            y_axis=\"duplication_rate\",\n",
    "            function=MM_duplication,\n",
    "            percentage_toplot=percentage_toplot,\n",
    "            plot_current_saturation=True,\n",
    "            svg_output_path=f\"plots_qc/{sample}__duplication_saturation.svg\",\n",
    "            png_output_path=f\"plots_qc/{sample}__duplication_saturation.png\",\n",
    "        )\n",
    "    else:\n",
    "        display(\n",
    "            Image(filename=f\"plots_qc/{sample}__duplication_saturation.png\", width=600)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d21918-0e7b-4d12-a6bc-7a0b3788bb23",
   "metadata": {},
   "source": [
    "## Combined plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da691462-b3e2-4e28-9261-a9a2b2ea4f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494a393a-a08b-4d07-aa25-00b9960b89b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_axis = \"mean_reads_per_barcode\"\n",
    "y_axis = \"median_uniq_frag_per_bc\"\n",
    "function = MM\n",
    "\n",
    "max_reads = 100000\n",
    "n_datapoints = int(max_reads / 1000 + 1)\n",
    "\n",
    "x_fit = np.linspace(0, max_reads, num=n_datapoints)  # fitting interval in n reads/cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ef9640-6871-4865-ad6c-1088e86ac335",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fit = pd.DataFrame()\n",
    "for sample in samples:\n",
    "    path = sampling_stats_path_dict[sample]\n",
    "    stats_df = pd.read_csv(path, sep=\"\\t\", index_col=0)\n",
    "    x_data = np.array(stats_df.loc[0:, x_axis])\n",
    "    y_data = np.array(stats_df.loc[0:, y_axis])\n",
    "\n",
    "    # fit to MM function\n",
    "    best_fit_ab, covar = curve_fit(function, x_data, y_data, bounds=(0, +np.inf))\n",
    "\n",
    "    # expand fit space\n",
    "    y_fit = function(x_fit, *(best_fit_ab))\n",
    "    df_fit_sub = pd.DataFrame()\n",
    "    df_fit_sub[y_axis] = y_fit\n",
    "    df_fit_sub[x_axis] = x_fit\n",
    "    df_fit_sub[\"sample\"] = sample\n",
    "    df_fit = pd.concat([df_fit, df_fit_sub])\n",
    "\n",
    "df_fit = df_fit.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5813b7-6535-4a54-9b68-29202ecc72e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data=df_fit, x=x_axis, y=y_axis, linewidth=3)\n",
    "plt.title(\"Samples Performance\")\n",
    "plt.ylabel(\"Median Unique Fragments/Cell\")\n",
    "plt.xlabel(\"Reads/Cell\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b844f8-1cc9-41e2-bc67-ae3f76b7974d",
   "metadata": {},
   "source": [
    "# Read-downsampled comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb254d9-630a-4779-acb6-44af230a7035",
   "metadata": {},
   "source": [
    "A common problem in these technical analyses is that all of your datasets are sequenced to different depths. Deeper sequencing will lead to more fragments detected per cell. For the most technically sound comparison, you should downsample all of your sequencing data to the highest common depth available, and then re-map the downsampled datasets. We did this in our 2023 NBT benchmark, but this is computationally expensive and takes a long time. A smarter approach is to use the saturation curves that we computed previously.  \n",
    "  \n",
    "A list of all the saturation curves that we calculated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b975d4af-242b-4bb9-a543-450bcd40ecd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sampling_stats_path_dict = {\n",
    "    x.split(\"/\")[-1].split(\".sampling\")[0]: x\n",
    "    for x in sorted(glob.glob(f\"{saturation_stats_path}/*.sampling_stats.tsv\"))\n",
    "}\n",
    "sampling_stats_path_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3cb634-0d2e-4875-88c8-18b642b08956",
   "metadata": {},
   "source": [
    "Then, we need to find the common depth to in-silico downsample all the samples to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc8edf1-cf83-4abb-8d1b-ffd5ca4d84fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_stats[\"rpc\"] = df_stats[\"n_reads\"] / df_stats[\"n_cells\"]\n",
    "min_rpc = df_stats[\"rpc\"].min()\n",
    "min_rpc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404ca60c-ee25-4fbe-8a7d-68423fc8c689",
   "metadata": {},
   "source": [
    "In the standard case, I will set the downsampling depth `to_downsample` as equal to `min_rpc`. Of course, you can change `to_downsample` to your liking (since we can even extrapolate values). If you downsample too much, you will favour methods that saturate faster. The inverse is also true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d999298f-2295-41d4-8016-1bd9ef5dd7a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "to_downsample = 20000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5eb82b8-c390-460d-bf43-fb1b77b25f3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T14:17:18.127426Z",
     "iopub.status.busy": "2023-07-27T14:17:18.127020Z",
     "iopub.status.idle": "2023-07-27T14:17:18.132119Z",
     "shell.execute_reply": "2023-07-27T14:17:18.131303Z",
     "shell.execute_reply.started": "2023-07-27T14:17:18.127401Z"
    }
   },
   "source": [
    "Now, for every sample, calculate the expected median unique number of fragments per barcode at `to_downsample` reads per cell (as well as unique and total number of fragments in the fragments file to calculate duplication):."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7688091-6b52-4c8d-9570-70f91c85170c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "to_downsample_projected_stats = pd.DataFrame()\n",
    "for sample in samples:\n",
    "    for variable in [\n",
    "        \"median_uniq_frag_per_bc\",\n",
    "        \"total_unique_frag_count\",\n",
    "        \"total_frag_count\",\n",
    "    ]:\n",
    "        print(variable)\n",
    "        to_downsample_projected_stats.at[sample, variable] = pum.get_fit(\n",
    "            sampling_stats_path_dict[sample],\n",
    "            alias_dict[sample],\n",
    "            df_stats.at[sample, \"n_reads\"],\n",
    "            df_stats.at[sample, \"n_cells\"],\n",
    "            x_axis=\"mean_reads_per_barcode\",\n",
    "            y_axis=variable,\n",
    "            function=MM,\n",
    "            to_downsample=to_downsample,\n",
    "            maxfev=5000,\n",
    "        )\n",
    "    to_downsample_projected_stats.at[sample, \"total_reads\"] = (\n",
    "        min_rpc * df_stats.at[sample, \"n_cells\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51067546-5f6c-40d8-811c-30805a6954d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "to_downsample_projected_stats.index = [\n",
    "    alias_dict[x] for x in to_downsample_projected_stats.index\n",
    "]\n",
    "to_downsample_projected_stats[\"duplication_rate\"] = 1 - (\n",
    "    to_downsample_projected_stats[\"total_unique_frag_count\"]\n",
    "    / to_downsample_projected_stats[\"total_frag_count\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9582fe-2bc5-46cc-9476-a2f84545c81c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T13:58:43.269314Z",
     "iopub.status.busy": "2023-07-27T13:58:43.268913Z",
     "iopub.status.idle": "2023-07-27T13:58:43.273769Z",
     "shell.execute_reply": "2023-07-27T13:58:43.273028Z",
     "shell.execute_reply.started": "2023-07-27T13:58:43.269289Z"
    }
   },
   "source": [
    "So, at a sequencing depth of `to_downsample` reads per cell, we can expect the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29075c5f-efda-4ac5-a94b-48befc975251",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "to_downsample_projected_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513b823a-e908-47e3-8339-30c7e36d1822",
   "metadata": {},
   "source": [
    "Note that `total_unique_frag_count` and `total_frag_count` and thus `duplication_rate` are for valid cell barcodes only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2b6754-defd-46b1-a31e-910108a1011f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(dpi=300, figsize=(len(to_downsample_projected_stats) * 0.5, 4))\n",
    "sns.barplot(\n",
    "    data=to_downsample_projected_stats,\n",
    "    x=to_downsample_projected_stats.index,\n",
    "    y=\"median_uniq_frag_per_bc\",\n",
    "    ax=ax,\n",
    ")\n",
    "plt.title(f\"Median unique fragments per cell at {int(to_downsample/1000)}k RPC\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.savefig(\"plots_qc/all_saturation_frags.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdaf9034-391a-4f31-97f2-52e9e51208d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(dpi=300, figsize=(len(to_downsample_projected_stats) * 0.5, 4))\n",
    "sns.barplot(\n",
    "    data=to_downsample_projected_stats,\n",
    "    x=to_downsample_projected_stats.index,\n",
    "    y=\"duplication_rate\",\n",
    "    ax=ax,\n",
    ")\n",
    "plt.title(f\"Duplication rate at {int(to_downsample/1000)}k RPC\")\n",
    "plt.xticks(rotation=45, ha=\"right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4133c0de-9835-4779-b8a6-ece4472e3bf0",
   "metadata": {},
   "source": [
    "With this information, we can adjust the sequencing efficiency stacked barplots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce43a44a-3ebc-46bf-bd3c-7220eb2661f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "to_downsample_projected_stats.index = [\n",
    "    {alias_dict[x]: x for x in alias_dict.keys()}[x]\n",
    "    for x in to_downsample_projected_stats.index\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ea0224-6aa3-49c0-9465-5ad82e84f630",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fraction_left = 1 - df_stats_merged[\n",
    "    [\n",
    "        \"No correct barcode\",\n",
    "        \"Not mapped properly\",\n",
    "        \"Fragments in noise barcodes\",\n",
    "    ]\n",
    "].sum(axis=1)\n",
    "\n",
    "df_stats_merged[\"Duplicate fragments in cells (downsampled)\"] = (\n",
    "    (\n",
    "        to_downsample_projected_stats[\"total_frag_count\"]\n",
    "        - to_downsample_projected_stats[\"total_unique_frag_count\"]\n",
    "    )\n",
    "    / to_downsample_projected_stats[\"total_frag_count\"]\n",
    "    * fraction_left\n",
    ")\n",
    "\n",
    "median_frip = (\n",
    "    df_stats_merged[\"total_nr_unique_frag_in_selected_barcodes_in_regions\"]\n",
    "    / df_stats_merged[\"total_nr_unique_frag_in_selected_barcodes\"]\n",
    ")\n",
    "\n",
    "df_stats_merged[\"Unique, in cells, in peaks (downsampled)\"] = median_frip * (\n",
    "    fraction_left - df_stats_merged[\"Duplicate fragments in cells (downsampled)\"]\n",
    ")\n",
    "\n",
    "df_stats_merged[\"Unique, in cells, not in peaks (downsampled)\"] = (\n",
    "    (1 - median_frip)\n",
    ") * (fraction_left - df_stats_merged[\"Duplicate fragments in cells (downsampled)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcffd12-883d-4660-9dde-168b1d087109",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pum.plot_losses_downsampled(\n",
    "    df_stats_merged=df_stats_merged,\n",
    "    sample_order=samples,\n",
    "    sample_alias_dict=alias_dict,\n",
    "    tech_order=[\"user_sample\"],\n",
    "    svg_output_path=\"plots_qc/usersamples_barplots_downsampled.svg\",\n",
    "    png_output_path=\"plots_qc/usersamples_barplots_downsampled.png\",\n",
    "    depth=to_downsample,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69e7cd5-765f-4ec0-96f8-f10727bd14af",
   "metadata": {},
   "source": [
    "Note that this is an approximation, as we do not re-filter cells. In reality, downsampling the dataset will most likely have an effect on the cell selection process. The magnitude of this effect will depend on the separation quality between true cells and noise. When true cells separate well from noise, downsampling has little effect."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cistopic_20230504",
   "language": "python",
   "name": "cistopic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
